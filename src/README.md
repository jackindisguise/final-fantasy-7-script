`generate-kanji-order.js`
---
Creates kanji lists from `kanji.JSON` and places them in `../kanji/`.

`generate-kanji-readme.js`
---
Generate data regarding kanji in each scene and places it in `../kanji/README.md`.

`generate_kanji_table.js`
---
Generates a Kanji table and stores it in `kanji.JSON` for use in other scripts.

`generate-scene-tables.js`
---
Generates markdown tables with all scenes founds in `../scene/processed/` and stores them in `../scene/tabulated/`.

`generate-split-script.js`
---
Split the English and Japanese entries for each line in each scene.

Stores them in a separate file `../scene/split/english/` and `../scene/split/Japanese/`.

`generate-vocabulary-list.js`
---
Generates a list of all vocabulary in every scene found in `../scene/processed/`.

The lists generated are JSON Files, stored in `../vocabulary/unprocessed/`, and they contain all definitions returned from a jsdict lookup.

Need to be run through the `vocab-disambiguator-webserver` app to generate the final vocabulary list for each scene.

`jsdict-lookup.js`
---
Loads the jsdict dictionary into memory and then provides a function for looking up words in it.

`kana-converter.json`
---
This is a table of hiragana and katakana that aides in the process of converting hiragana to katakana and vice versa.

`kanji.json`
---
Auto-generated file with info regarding all the kanji found in the script.

`latest.js`
---
Produces a single line link to the latest update, for use with Ankiweb.

`mecab-symbols.js`
---
Shortcuts for parsing symbols in what Mecab returns.

`mecab-wrapper.js`
---
This is a quick wrapper for the commandline Mecab tool. Mecab is a Japanese tokenizer.
It returns individuals units of language in Japanese, which allows me to pretty accurately
scrape words from a Japanese sentence.

`process_all.js`
---
Automatically processes all formatted scenes in `../scene/formatted`

`process.js`
---
Exports the `process()` function for parsing formatted script text.

This function is very simple. It accepts 1 argument (the full text of the script) and does a few things:
* collapses all quote blocks in the English script (blocks that start with opening quotations “ and end with closing quotations ”) into 1 line;
* collapses all quote blocks in the Japanese script (blocks that start with opening brackets 「 and end with closing brackets 」) into 1 line;
* detects the beginning of quote blocks before the end of a quote block, and assumes the previous quote block ends there;
* removes all empty lines from both scripts;

Due to inconsistencies in the source spreadsheet, you have to do quite a lot of manual fixes. Most of them consist of:
* adding missing closing markers;
* adding opening and closing markers;
* removing incorrectly placed closing markers;
* replacing inconsistent opening/closing markers;
* re-combining dialogue that was split into multiple boxes due to space requirements (and other reasons) in the translated text;
* adding missing translations.

The ultimate goal is to have it so that the text in the English script has the exact same number of "lines" as the text in the Japanese script. Once all this formatting is done, each line in the English script is attached to the same line in the Japanese script. Matching lines is the only important thing.

The format of the processed text should be thus:

>`<English line>` `\t` `<Japanese line>`

`quick.js`
---
Processes the formatted script from `formatted.txt` and pops out the processed script in `processed.txt`.

`vocab-disambiguator-webserver.js`
---
Opens an app that runs through a local webserver.

This app allows you to quickly and easily disambiguate words found in each scene.

Uses vocabulary files generated by `generate-vocabulary-list.js`.